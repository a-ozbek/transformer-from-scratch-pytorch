{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](./transformer-basics.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicTransformer:\n",
    "    \"\"\"\n",
    "    Basic Transformer\n",
    "    \"\"\"\n",
    "    def __init__(self, dim):\n",
    "        self.dim = dim\n",
    "        self.W_q = torch.rand(dim, dim, requires_grad=True)\n",
    "        self.W_k = torch.rand(dim, dim, requires_grad=True)\n",
    "        self.W_v = torch.rand(dim, dim, requires_grad=True)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: \n",
    "            dim0: batch dimension\n",
    "            cols: timesteps (or sequence)\n",
    "            rows: dimensionality (dim)\n",
    "        \"\"\"\n",
    "        q = torch.matmul(self.W_q, x)\n",
    "        k = torch.matmul(self.W_k, x)\n",
    "        v = torch.matmul(self.W_v, x)  # 32 x 8 x 17\n",
    "        \n",
    "        batch_size = x.shape[0]\n",
    "        timesteps = x.shape[2]\n",
    "        \n",
    "        y = torch.empty(batch_size, self.dim, timesteps)\n",
    "        \n",
    "        for i in range(timesteps):\n",
    "            q_i = q[:, :, i]\n",
    "            # get weights\n",
    "            weights = torch.matmul(q_i[:, np.newaxis, :], k).squeeze()\n",
    "            # scale weights\n",
    "            weights = weights / np.sqrt(self.dim)\n",
    "            # softmax weights\n",
    "            weights = torch.softmax(weights, dim=1)\n",
    "            \n",
    "            y[:, :, i] = torch.sum(weights[:, np.newaxis, :] * v, dim=2)\n",
    "        \n",
    "        y = y.mean(dim=2)  # average out the sequence\n",
    "            \n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BasicTransformer(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ = torch.rand(32, 8, 17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Dimension out of range (expected to be in range of [-2, 1], but got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-97b102ab9ffc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-36-0b99e3c09f65>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0my_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m             \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_i\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# average out the sequence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Dimension out of range (expected to be in range of [-2, 1], but got 2)"
     ]
    }
   ],
   "source": [
    "y = model.forward(x_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 8, 17])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 8])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.mean(dim=2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights.shape: torch.Size([32, 17])\n",
      "weights.shape: torch.Size([32, 17])\n",
      "weights.shape: torch.Size([32, 17])\n",
      "weights.shape: torch.Size([32, 17])\n",
      "weights.shape: torch.Size([32, 17])\n",
      "weights.shape: torch.Size([32, 17])\n",
      "weights.shape: torch.Size([32, 17])\n",
      "weights.shape: torch.Size([32, 17])\n",
      "weights.shape: torch.Size([32, 17])\n",
      "weights.shape: torch.Size([32, 17])\n",
      "weights.shape: torch.Size([32, 17])\n",
      "weights.shape: torch.Size([32, 17])\n",
      "weights.shape: torch.Size([32, 17])\n",
      "weights.shape: torch.Size([32, 17])\n",
      "weights.shape: torch.Size([32, 17])\n",
      "weights.shape: torch.Size([32, 17])\n",
      "weights.shape: torch.Size([32, 17])\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 17])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.0819e-02, 1.4097e-03, 5.4635e-03, 6.4457e-03, 4.0511e-03, 1.1580e-03,\n",
       "         7.0004e-01, 1.4089e-03, 6.2278e-04, 9.4176e-04, 5.6552e-02, 1.8018e-01,\n",
       "         5.4823e-03, 1.5045e-03, 3.4460e-03, 8.7194e-03, 1.7479e-03],\n",
       "        [1.1504e-03, 2.4111e-03, 9.0321e-02, 9.4621e-02, 6.8310e-03, 3.0312e-02,\n",
       "         1.2864e-02, 1.1005e-01, 1.4621e-02, 1.5085e-03, 2.3201e-03, 1.0446e-03,\n",
       "         8.6780e-02, 2.7091e-03, 1.3246e-04, 2.3951e-02, 5.1837e-01],\n",
       "        [1.1220e-02, 5.5838e-03, 1.7391e-01, 3.0684e-02, 3.6276e-04, 1.4706e-02,\n",
       "         1.4670e-01, 9.0861e-02, 5.8181e-02, 1.8195e-02, 3.1755e-01, 1.8231e-03,\n",
       "         4.3236e-03, 3.2926e-02, 5.2640e-02, 1.7787e-02, 2.2547e-02],\n",
       "        [3.8560e-03, 2.9235e-01, 2.4944e-03, 2.7203e-03, 1.8404e-02, 8.3394e-03,\n",
       "         5.0762e-02, 1.7592e-03, 3.6783e-02, 1.2011e-02, 1.3927e-02, 1.0578e-02,\n",
       "         1.5957e-01, 7.6049e-02, 1.4316e-02, 2.9308e-01, 3.0050e-03],\n",
       "        [1.6832e-04, 1.0130e-03, 5.0239e-02, 1.4779e-04, 1.8104e-01, 7.1259e-03,\n",
       "         7.4451e-05, 1.4982e-05, 5.4818e-03, 9.6766e-05, 3.1198e-01, 1.0968e-01,\n",
       "         2.0093e-02, 1.2354e-04, 1.1637e-01, 3.1727e-04, 1.9603e-01],\n",
       "        [7.9352e-03, 1.0019e-01, 3.3401e-04, 4.3322e-03, 2.5252e-02, 3.7735e-05,\n",
       "         1.7435e-03, 4.8498e-02, 3.1476e-04, 5.4842e-02, 1.2509e-02, 2.5724e-03,\n",
       "         9.5465e-03, 4.5218e-04, 7.2706e-03, 7.1712e-01, 7.0470e-03],\n",
       "        [1.4022e-03, 2.0496e-03, 4.7972e-03, 4.2308e-02, 5.4332e-03, 3.2138e-02,\n",
       "         5.8834e-02, 9.5126e-03, 1.8931e-02, 4.8512e-02, 4.4622e-03, 4.3852e-01,\n",
       "         5.3084e-02, 3.5608e-03, 1.7376e-01, 9.7107e-02, 5.5879e-03],\n",
       "        [2.0064e-02, 7.1504e-03, 2.4288e-03, 1.7883e-02, 5.0207e-04, 6.0250e-03,\n",
       "         1.6305e-04, 3.6327e-03, 1.5832e-04, 2.1120e-03, 1.3029e-02, 2.9849e-04,\n",
       "         1.4586e-03, 9.1985e-01, 3.4030e-04, 1.3689e-03, 3.5357e-03],\n",
       "        [2.1111e-02, 2.7690e-01, 1.4845e-02, 4.6007e-01, 7.9620e-03, 1.7020e-03,\n",
       "         4.9896e-03, 3.3067e-03, 1.7019e-02, 7.7734e-03, 1.2961e-01, 3.4566e-03,\n",
       "         4.4704e-03, 1.8353e-02, 1.1741e-02, 1.3742e-02, 2.9444e-03],\n",
       "        [1.7524e-02, 1.8118e-03, 3.9247e-04, 2.6103e-04, 7.8354e-04, 1.1269e-03,\n",
       "         1.0819e-01, 4.4120e-02, 6.1500e-02, 3.8173e-01, 1.8193e-04, 1.1213e-04,\n",
       "         2.1969e-01, 5.0526e-03, 1.0819e-03, 1.3976e-03, 1.5504e-01],\n",
       "        [8.9472e-04, 1.9987e-01, 1.7548e-01, 1.3122e-03, 1.0779e-03, 5.8829e-04,\n",
       "         6.6442e-03, 1.9610e-02, 1.3243e-02, 4.5677e-04, 3.4226e-03, 1.5192e-02,\n",
       "         1.6628e-01, 6.7676e-02, 1.0670e-03, 2.6467e-01, 6.2526e-02],\n",
       "        [1.2382e-01, 6.2496e-03, 1.1610e-02, 1.3492e-01, 1.4556e-02, 6.6173e-02,\n",
       "         4.5907e-02, 3.5427e-02, 7.8030e-02, 7.9195e-02, 1.1396e-02, 3.7567e-02,\n",
       "         1.5512e-02, 9.9070e-02, 1.4413e-02, 2.1302e-01, 1.3132e-02],\n",
       "        [5.6534e-05, 4.3020e-02, 1.3244e-04, 6.2246e-03, 1.3004e-03, 3.5649e-03,\n",
       "         5.7472e-04, 3.4577e-04, 3.0270e-02, 1.8216e-03, 4.8483e-03, 2.0276e-05,\n",
       "         9.6833e-02, 4.4727e-03, 5.1878e-02, 5.5585e-05, 7.5458e-01],\n",
       "        [1.1426e-03, 2.7834e-03, 3.7891e-02, 1.1077e-03, 6.8278e-03, 9.0544e-03,\n",
       "         3.8454e-01, 6.9312e-03, 2.1484e-02, 3.0698e-03, 1.1065e-02, 4.0673e-02,\n",
       "         7.6235e-02, 3.3647e-01, 5.1783e-03, 9.1840e-03, 4.6367e-02],\n",
       "        [1.3599e-02, 4.6124e-01, 7.6325e-04, 1.6505e-04, 2.3003e-01, 1.2124e-02,\n",
       "         2.1538e-02, 1.5885e-01, 2.3849e-02, 2.4001e-02, 5.3515e-03, 2.8433e-03,\n",
       "         1.5611e-03, 8.6128e-03, 2.7877e-03, 2.3896e-02, 8.7880e-03],\n",
       "        [5.4513e-01, 3.2815e-03, 2.5458e-03, 2.5189e-03, 2.1506e-02, 2.0170e-02,\n",
       "         1.0437e-04, 3.1022e-03, 8.6769e-03, 2.9752e-01, 3.3831e-03, 6.3358e-04,\n",
       "         8.5801e-02, 6.8708e-04, 9.0827e-04, 8.9924e-04, 3.1349e-03],\n",
       "        [5.9899e-03, 1.1239e-03, 2.7603e-01, 1.7133e-02, 7.4168e-04, 2.5369e-02,\n",
       "         5.1390e-02, 5.9014e-03, 5.1012e-04, 4.4278e-03, 8.9669e-04, 3.9693e-02,\n",
       "         8.2899e-03, 1.8044e-02, 7.4773e-03, 4.9415e-01, 4.2833e-02],\n",
       "        [2.1420e-02, 4.8473e-02, 1.9409e-03, 6.9675e-03, 5.9496e-03, 7.9704e-03,\n",
       "         2.9351e-01, 7.5752e-02, 7.7752e-03, 2.9691e-01, 1.0049e-02, 1.4899e-01,\n",
       "         1.8044e-02, 3.6877e-03, 4.7158e-02, 1.6270e-03, 3.7760e-03],\n",
       "        [5.4362e-02, 1.5654e-03, 1.1317e-01, 2.9676e-02, 4.2740e-01, 4.4792e-02,\n",
       "         1.7398e-03, 1.9743e-02, 4.2676e-03, 8.9942e-04, 1.2217e-02, 8.2114e-03,\n",
       "         4.9658e-03, 9.0626e-02, 1.5617e-01, 1.9684e-02, 1.0517e-02],\n",
       "        [7.9994e-02, 1.2538e-02, 5.4640e-01, 3.0171e-02, 1.3186e-03, 1.3028e-02,\n",
       "         2.6725e-03, 2.4416e-03, 1.0463e-01, 1.0830e-03, 3.2623e-03, 1.1296e-02,\n",
       "         5.3418e-03, 2.1108e-03, 4.8881e-03, 1.7740e-01, 1.4161e-03],\n",
       "        [2.4373e-01, 5.7210e-02, 4.1232e-02, 1.3627e-04, 9.1305e-02, 5.8467e-03,\n",
       "         3.4537e-01, 3.6490e-02, 1.0166e-02, 5.0382e-02, 1.8870e-02, 2.1785e-02,\n",
       "         1.5006e-02, 4.4608e-02, 4.8929e-04, 1.4193e-02, 3.1853e-03],\n",
       "        [3.4396e-03, 3.0353e-04, 1.5478e-02, 2.8951e-02, 1.7959e-02, 8.4147e-03,\n",
       "         3.9982e-03, 1.9477e-01, 4.7673e-04, 1.1548e-01, 6.0877e-02, 1.0913e-01,\n",
       "         4.0913e-01, 7.7341e-03, 1.0924e-02, 1.6103e-03, 1.1334e-02],\n",
       "        [1.1891e-02, 4.1475e-03, 8.5641e-02, 5.4926e-03, 2.6746e-03, 3.3299e-02,\n",
       "         5.7911e-03, 2.3509e-01, 1.3971e-01, 2.3985e-02, 6.2930e-02, 6.9761e-03,\n",
       "         7.6779e-02, 5.2011e-03, 2.2509e-01, 6.7084e-02, 8.2243e-03],\n",
       "        [5.3175e-01, 1.0983e-02, 1.1808e-03, 2.1645e-02, 1.4144e-02, 5.6780e-02,\n",
       "         1.5611e-02, 2.9963e-03, 7.7580e-03, 3.1363e-03, 6.4003e-03, 1.4761e-01,\n",
       "         3.0123e-03, 4.3624e-02, 8.5020e-02, 4.6476e-02, 1.8658e-03],\n",
       "        [2.7584e-02, 6.0607e-02, 5.7041e-02, 7.0971e-02, 6.1151e-04, 9.0255e-02,\n",
       "         6.7607e-02, 1.6347e-01, 8.7871e-02, 5.1386e-03, 4.7664e-03, 4.7976e-04,\n",
       "         2.6138e-01, 9.1310e-03, 5.2615e-04, 8.9264e-02, 3.2920e-03],\n",
       "        [8.4912e-02, 1.9427e-02, 2.0632e-02, 3.7944e-02, 2.9256e-02, 1.8159e-02,\n",
       "         6.8354e-03, 1.3614e-01, 5.0714e-03, 6.2389e-03, 2.9507e-02, 2.5153e-01,\n",
       "         5.6269e-02, 1.9647e-02, 1.6148e-02, 2.5917e-01, 3.1065e-03],\n",
       "        [1.5002e-01, 4.4049e-04, 7.4683e-03, 9.4519e-02, 1.3517e-02, 7.2364e-02,\n",
       "         6.0879e-03, 6.4995e-02, 7.6176e-02, 4.1717e-02, 9.4493e-04, 1.3556e-02,\n",
       "         8.5327e-02, 6.0445e-02, 1.8177e-01, 2.4515e-02, 1.0614e-01],\n",
       "        [3.4022e-02, 2.7912e-03, 8.5066e-05, 1.2094e-03, 2.7032e-02, 6.9473e-01,\n",
       "         8.6823e-02, 2.4372e-02, 5.6798e-03, 5.1152e-02, 6.4355e-04, 1.4689e-02,\n",
       "         2.0777e-02, 5.1206e-04, 7.5647e-04, 2.8825e-02, 5.8975e-03],\n",
       "        [2.2711e-02, 1.4299e-04, 7.1602e-05, 1.7310e-05, 1.3106e-04, 5.6863e-04,\n",
       "         3.1936e-04, 2.4014e-01, 6.9465e-01, 1.7599e-03, 2.2403e-03, 1.1814e-03,\n",
       "         2.2322e-03, 1.8182e-04, 1.0042e-04, 3.1119e-02, 2.4389e-03],\n",
       "        [4.6971e-03, 5.1269e-01, 1.4525e-03, 6.7125e-04, 4.7440e-04, 7.7096e-04,\n",
       "         7.3587e-05, 5.1536e-03, 6.3722e-04, 1.8932e-02, 5.7651e-03, 2.7427e-03,\n",
       "         6.0133e-04, 9.9749e-04, 1.4805e-03, 4.4175e-01, 1.1165e-03],\n",
       "        [3.4897e-02, 2.2474e-02, 9.6882e-03, 1.2270e-04, 1.3282e-02, 1.0831e-02,\n",
       "         1.6605e-02, 4.5491e-01, 1.3048e-03, 2.5944e-02, 1.3013e-03, 2.1999e-04,\n",
       "         1.3933e-04, 2.2776e-01, 2.5777e-02, 1.4292e-01, 1.1826e-02],\n",
       "        [1.5157e-03, 5.0438e-04, 2.5739e-07, 2.0837e-04, 1.0368e-03, 4.4899e-05,\n",
       "         7.0195e-04, 2.6914e-04, 4.4300e-04, 1.1495e-02, 9.5944e-01, 1.5238e-04,\n",
       "         2.1200e-06, 5.2086e-03, 9.2309e-05, 2.8943e-05, 1.8859e-02]],\n",
       "       grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmaxed_weights = torch.softmax(weights, dim=1)\n",
    "softmaxed_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.empty(2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = torch.rand(32, 8)\n",
    "x2 = torch.rand(32, 8, 17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "o = torch.matmul(x1[:, np.newaxis, :], x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 17])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o.squeeze().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 8, 17])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x1[..., np.newaxis] * x2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_ = torch.rand(3, 8)\n",
    "X_ = torch.rand(32, 8, 17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "O_ = torch.matmul(W_, X_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3, 17])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "O_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
