{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import comet_ml\n",
    "import os\n",
    "import json\n",
    "import multiprocessing\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from ml_util.monitor.comet_ml_exp import initialize_comet_ml_experiment\n",
    "from basic_transformer.models.basic_transformer import BasicTransformer\n",
    "from basic_transformer import utils as local_util\n",
    "RANDOM_SEED = 43\n",
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_VERSION = 'x.0.0'\n",
    "DATASET = 'yelp'  # 'yelp' or 'imdb'\n",
    "N_SAMPLE_YELP = 50_000\n",
    "TEST_SIZE = 0.2\n",
    "#\n",
    "N_EPOCHS = 5\n",
    "DIM = 16\n",
    "NUM_WORDS = 5_000\n",
    "MAX_SEQ_LEN = 128\n",
    "#\n",
    "TEXT_COLUMN = 'review'\n",
    "LABEL_COLUMN = 'sentiment'\n",
    "LABEL_MAPPING = {'negative': 0, 'positive': 1}\n",
    "# dataloaders\n",
    "BATCH_SIZE = 16\n",
    "SHUFFLE = True\n",
    "DEBUG_DF = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if DATASET == 'yelp':\n",
    "    df = pd.read_csv(\"/media/can/datasets/yelp/df.csv\")\n",
    "    df['sentiment'] = df['stars'].replace({1: 'negative', 5: 'positive'})\n",
    "    df = df.rename(columns={'text': 'review'})\n",
    "    df = df.sample(n=N_SAMPLE_YELP, random_state=RANDOM_SEED)\n",
    "elif DATASET == 'imdb':\n",
    "    df = pd.read_csv(\"/media/can/datasets/imdb-50k-movie-review/IMDB Dataset.csv\")\n",
    "else:\n",
    "    raise ValueError(\"Invalid data: {}\".format(str(DATASET)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train - test split \n",
    "df_train, df_test = train_test_split(df, test_size=TEST_SIZE)\n",
    "del df\n",
    "print(\"len(df_train):\", len(df_train))\n",
    "print(\"len(df_test):\", len(df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_dataset_params = dict()\n",
    "text_dataset_params['num_words'] = NUM_WORDS\n",
    "text_dataset_params['text_column'] = TEXT_COLUMN\n",
    "text_dataset_params['label_column'] = LABEL_COLUMN\n",
    "text_dataset_params['label_mapping'] = LABEL_MAPPING\n",
    "text_dataset_params['max_seq_len'] = MAX_SEQ_LEN\n",
    "\n",
    "# datasets\n",
    "datagen_train = local_util.dataset_generator.TextDataset(df=df_train, **text_dataset_params)\n",
    "datagen_test = local_util.dataset_generator.TextDataset(df_test, \n",
    "                                                        **text_dataset_params, \n",
    "                                                        tokenizer=datagen_train.tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_params = dict()\n",
    "dataloader_params['batch_size'] = BATCH_SIZE\n",
    "dataloader_params['num_workers'] = multiprocessing.cpu_count()\n",
    "dataloader_params['shuffle'] = SHUFFLE\n",
    "\n",
    "# dataloaders\n",
    "dataloader_train = DataLoader(dataset=datagen_train, **dataloader_params)\n",
    "dataloader_test = DataLoader(dataset=datagen_test, **dataloader_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get model\n",
    "model = BasicTransformer(dim=DIM, num_embeddings=NUM_WORDS, embedding_dim=DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# initialize comet experiment\n",
    "COMET_ML_EXPERIMENT, \\\n",
    "COMET_ML_EXPERIMENT_LINK = initialize_comet_ml_experiment(model_name=local_util.config.PROJECT_NAME, \n",
    "                                                          model_version=MODEL_VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epoch_loss = local_util.math.AvgContainer()\n",
    "epoch_acc = local_util.math.AvgContainer()\n",
    "\n",
    "with COMET_ML_EXPERIMENT.train():\n",
    "    for epoch in range(N_EPOCHS):\n",
    "        p_bar = tqdm_notebook(enumerate(dataloader_train), total=len(dataloader_train))\n",
    "        for i, x in p_bar:\n",
    "            \n",
    "            inputs = x['seq']\n",
    "            labels = x['label'].float()\n",
    "\n",
    "            inputs = inputs.cuda()\n",
    "            labels = labels.cuda()\n",
    "\n",
    "            #\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # \n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # acc\n",
    "            y_true = labels.cpu().numpy().astype(np.int)\n",
    "            y_pred = (outputs > 0.5).cpu().numpy().astype(np.int).squeeze()\n",
    "            acc = np.mean(y_true == y_pred)\n",
    "            \n",
    "            # log\n",
    "            COMET_ML_EXPERIMENT.log_metric(\"batch_loss\", loss)\n",
    "            COMET_ML_EXPERIMENT.log_metric(\"batch_acc\", acc)\n",
    "            \n",
    "            # update avg\n",
    "            epoch_loss.update([loss.item()])\n",
    "            epoch_acc.update([acc])\n",
    "            p_bar.set_description(\"Epoch: {} - Loss: {} - Acc: {}\".format(str(epoch + 1),\n",
    "                                                                          \"{0:.3f}\".format(epoch_loss.avg), \n",
    "                                                                          \"{0:.3f}\".format(epoch_acc.avg)))\n",
    "        \n",
    "        # log\n",
    "        COMET_ML_EXPERIMENT.log_metric(\"epoch_loss\", epoch_loss.avg, step=epoch)\n",
    "        COMET_ML_EXPERIMENT.log_metric(\"epoch_acc\", epoch_acc.avg, step=epoch)\n",
    "        \n",
    "        # reset\n",
    "        epoch_loss.reset()\n",
    "        epoch_acc.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc = local_util.math.AvgContainer()\n",
    "acc_values = list()\n",
    "loss_values = list()\n",
    "y_true_list = list()\n",
    "y_pred_list = list()\n",
    "with COMET_ML_EXPERIMENT.test():\n",
    "    for i, x in tqdm_notebook(enumerate(dataloader_test), total=len(dataloader_test)):\n",
    "        inputs = x['seq']\n",
    "        labels = x['label'].float()\n",
    "\n",
    "        inputs = inputs.cuda()\n",
    "        labels = labels.cuda()\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        loss_values.append(loss)\n",
    "        \n",
    "        #\n",
    "        y_true = labels.cpu().numpy().astype(np.int)\n",
    "        y_pred = (outputs > 0.5).cpu().numpy().astype(np.int).squeeze()\n",
    "        acc = np.mean(y_true == y_pred)\n",
    "        acc_values.append(acc)\n",
    "        \n",
    "        test_acc.update([acc])\n",
    "        \n",
    "        # save \n",
    "        y_true_list += list(y_true)\n",
    "        y_pred_list += list(y_pred)\n",
    "\n",
    "print(\"Test Accuracy:\", test_acc.avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss values\n",
    "loss_values_ = [l.item() for l in tqdm_notebook(loss_values)]\n",
    "pd.Series(loss_values_).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "confusion_matrix(y_true_list, y_pred_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_SAVE_PATH = os.path.join(\"/media/can/MyData/models/\", local_util.config.PROJECT_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save train tokenizer\n",
    "pickle.dump(datagen_train.tokenizer, open(os.path.join(MODEL_SAVE_PATH, \"train_tokenizer.pkl\"), \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save pytorch model\n",
    "path_to_save = os.path.join(\"/media/can/MyData/models/\", local_util.config.PROJECT_NAME, \"model.pth\")\n",
    "torch.save(model.state_dict(), path_to_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen_train.tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[df_test['sentiment'] == 'negative']['review'].iloc[2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save entire model\n",
    "torch.save(model, os.path.join(\"/media/can/MyData/models/\", local_util.config.PROJECT_NAME, \"model_entire.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
