{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "import keras\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from basic_transformer.models.basic_transformer import BasicTransformer\n",
    "from basic_transformer import utils as local_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIM = 16\n",
    "NUM_WORDS = 10_000\n",
    "TEXT_COLUMN = 'review'\n",
    "LABEL_COLUMN = 'sentiment'\n",
    "LABEL_MAPPING = {'negative': 0, 'positive': 1}\n",
    "MAX_SEQ_LEN = 500\n",
    "# dataloaders\n",
    "BATCH_SIZE = 16\n",
    "SHUFFLE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get model\n",
    "model = BasicTransformer(dim=DIM, num_embeddings=NUM_WORDS, embedding_dim=DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(\"/media/can/MyData/datasets/yelp/df.csv\")\n",
    "df = pd.read_csv(\"/media/can/MyData/datasets/imdb-50k-movie-review/IMDB Dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = local_util.dataset_generator.TextDataset(df=df, \n",
    "                                                   num_words=NUM_WORDS, \n",
    "                                                   text_column=TEXT_COLUMN, \n",
    "                                                   label_column=LABEL_COLUMN, \n",
    "                                                   label_mapping=LABEL_MAPPING, \n",
    "                                                   max_seq_len=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset=datagen,  batch_size=BATCH_SIZE, num_workers=multiprocessing.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BasicTransformer(\n",
       "  (embed_layer): Embedding(10000, 16)\n",
       "  (linear): Linear(in_features=16, out_features=16, bias=True)\n",
       "  (linear_clf): Linear(in_features=16, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "914dc7deba0d4c3f90af60a7c0ef9760",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3125), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/can/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:1350: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/home/can/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py:498: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([16, 1])) is deprecated. Please ensure they have the same size.\n",
      "  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(0.9940, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(1.3804, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(1.0569, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.9178, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7328, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.8293, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7707, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7206, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6524, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7256, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7505, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6933, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6246, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7235, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7674, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6369, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7266, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6668, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7639, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7291, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6247, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7361, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7403, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6377, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7425, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6375, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7136, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7074, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6674, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7161, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6977, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7759, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7610, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7912, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7154, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6387, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7460, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6497, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7206, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6641, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7104, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7077, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6941, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7293, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6576, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6886, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7219, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7011, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6593, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6657, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6967, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7069, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7081, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6991, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7200, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6881, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7058, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7034, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6983, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6857, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6943, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6721, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6779, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7224, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6848, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6796, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6880, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6813, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6950, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6665, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7018, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7035, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6909, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7223, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7296, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7310, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6981, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7009, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6992, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7320, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7338, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6819, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6649, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7399, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6725, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7232, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7109, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6664, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7510, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7202, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7222, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6822, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6816, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6542, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6853, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7108, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6675, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6984, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "[1,   200] loss: 0.712\n",
      "loss: tensor(0.6862, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6995, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6928, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6911, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6772, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7015, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7158, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7039, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(0.6985, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7264, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6653, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6784, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6823, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6966, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6929, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6677, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6655, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7116, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6758, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7102, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6994, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7439, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7086, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6599, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6605, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7450, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7009, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6671, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6730, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6722, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7627, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7100, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7381, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6871, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6829, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6814, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6862, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7004, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7063, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7178, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6859, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6800, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7006, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6872, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6951, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6722, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6841, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6939, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6930, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6870, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6975, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6926, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6642, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6878, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7075, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6778, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6715, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6867, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7024, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7083, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7391, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6431, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6907, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6856, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6742, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6932, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6788, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6685, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6862, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6700, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7259, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6675, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7307, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6988, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6949, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6801, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7226, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6967, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6803, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7293, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6960, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7186, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6992, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7013, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7214, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7155, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7467, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7160, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6928, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6953, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7025, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7260, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6926, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7088, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6968, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6984, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6860, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6643, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6943, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6718, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "[1,   400] loss: 0.696\n",
      "loss: tensor(0.6865, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7100, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6818, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6757, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6671, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6707, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7233, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7146, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6466, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7088, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6661, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7631, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6724, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7293, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6725, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6757, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(0.6949, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6806, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6853, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6939, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7007, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6928, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6924, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6971, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6820, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6908, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6831, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6686, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7036, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7124, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7045, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6796, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7021, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7066, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6879, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6777, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7041, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7125, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6985, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7041, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6917, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7062, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6958, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7065, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7137, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6841, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7002, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6932, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7118, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7375, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6978, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6795, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6935, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6958, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7088, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6876, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7002, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6812, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6930, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6730, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7077, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6874, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6746, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7114, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6709, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7234, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6929, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6868, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6746, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6989, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7020, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6902, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6893, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7022, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6899, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6868, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7052, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6947, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7151, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6614, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6983, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7057, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6911, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6796, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6860, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6921, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7125, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7050, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6819, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6927, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6934, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6813, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7059, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7021, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6924, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6770, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6924, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6613, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7088, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7029, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "[1,   600] loss: 0.695\n",
      "loss: tensor(0.6718, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6991, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6878, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7227, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6618, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7264, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6852, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6832, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7126, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6865, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6742, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6831, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6971, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7040, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6874, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7060, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7076, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7010, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6796, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6986, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7252, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6916, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6982, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(0.7169, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7294, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6789, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6626, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6754, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7008, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6967, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7192, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7039, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6801, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7189, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6744, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7285, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6749, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6819, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7284, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6968, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7250, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6774, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6511, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6908, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6788, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6372, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7004, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7058, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6874, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6886, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6942, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6958, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6951, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6550, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6859, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6800, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6749, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7048, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7276, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6865, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6746, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7371, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7112, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6630, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6810, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6801, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7021, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6709, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7063, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6868, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6829, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6854, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6846, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7012, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7092, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6855, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6920, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6438, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7228, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6995, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6856, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6949, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6955, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7254, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6696, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6627, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6911, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6888, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7087, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7099, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6901, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6994, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6890, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6772, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7090, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6978, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6817, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6894, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7012, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "[1,   800] loss: 0.694\n",
      "loss: tensor(0.6975, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7014, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6632, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6657, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7066, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7075, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6786, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6984, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6612, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7123, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6687, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6820, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7177, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7640, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6954, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7266, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6936, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7036, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6838, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6752, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6980, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6930, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6981, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7011, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7143, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7057, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6775, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6621, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6588, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7134, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7085, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7119, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(0.6857, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6883, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7265, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7474, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6985, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6560, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7141, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6715, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7060, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6733, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6698, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6829, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6945, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6945, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6976, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6758, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6771, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6751, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7040, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6876, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6966, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7524, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7037, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7034, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6857, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6743, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6777, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6636, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6942, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6799, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6828, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6543, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7388, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6734, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6742, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6731, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7659, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7035, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7065, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6838, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6940, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7176, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7107, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7306, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6790, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6997, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6793, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6929, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6874, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6723, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6811, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6837, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6739, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7229, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7240, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6985, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6736, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7025, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6781, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7007, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7134, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6709, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7043, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6803, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6920, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6911, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7163, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "[1,  1000] loss: 0.694\n",
      "loss: tensor(0.7468, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7021, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7002, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6715, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6977, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7353, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6909, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7014, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7026, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6897, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7133, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7081, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6942, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6874, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7031, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.7033, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6979, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6804, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6921, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "loss: tensor(0.6686, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/can/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3296, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-10-299e5cbde9d4>\", line 18, in <module>\n",
      "    loss.backward()\n",
      "  File \"/home/can/anaconda3/lib/python3.7/site-packages/torch/tensor.py\", line 118, in backward\n",
      "    torch.autograd.backward(self, gradient, retain_graph, create_graph)\n",
      "  File \"/home/can/anaconda3/lib/python3.7/site-packages/torch/autograd/__init__.py\", line 93, in backward\n",
      "    allow_unreachable=True)  # allow_unreachable flag\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/can/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2033, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/can/anaconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1095, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/can/anaconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 313, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/can/anaconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 347, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/home/can/anaconda3/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/home/can/anaconda3/lib/python3.7/inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/home/can/anaconda3/lib/python3.7/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/home/can/anaconda3/lib/python3.7/inspect.py\", line 742, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"/home/can/anaconda3/lib/python3.7/posixpath.py\", line 395, in realpath\n",
      "    path, ok = _joinrealpath(filename[:0], filename, {})\n",
      "  File \"/home/can/anaconda3/lib/python3.7/posixpath.py\", line 429, in _joinrealpath\n",
      "    if not islink(newpath):\n",
      "  File \"/home/can/anaconda3/lib/python3.7/posixpath.py\", line 171, in islink\n",
      "    st = os.lstat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "losses = list()\n",
    "running_loss = 0.0\n",
    "every = 200\n",
    "for epoch in range(2):\n",
    "    for i, x in tqdm_notebook(enumerate(dataloader), total=len(dataloader)):\n",
    "        inputs = x['seq']\n",
    "        labels = x['label'].float()\n",
    "\n",
    "        inputs = inputs.cuda()\n",
    "        labels = labels.cuda()\n",
    "\n",
    "        #\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # \n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if i % 2 == 0:\n",
    "            print('loss:', loss)\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % every == every - 1:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / every))\n",
    "            running_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_layer = torch.nn.Embedding(num_embeddings=17, embedding_dim=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# emb_layer(torch.tensor([0, 0, 10, 16, 17]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
