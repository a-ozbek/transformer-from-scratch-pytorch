{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import comet_ml\n",
    "import os\n",
    "import json\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "import keras\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from ml_util.monitor.comet_ml_exp import initialize_comet_ml_experiment\n",
    "from basic_transformer.models.basic_transformer import BasicTransformer\n",
    "from basic_transformer import utils as local_util\n",
    "RANDOM_SEED = 43\n",
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = 'yelp'  # 'yelp' or 'imdb'\n",
    "DIM = 128\n",
    "NUM_WORDS = 5_000\n",
    "TEXT_COLUMN = 'review'\n",
    "LABEL_COLUMN = 'sentiment'\n",
    "LABEL_MAPPING = {'negative': 0, 'positive': 1}\n",
    "MAX_SEQ_LEN = 128\n",
    "# dataloaders\n",
    "BATCH_SIZE = 16\n",
    "SHUFFLE = True\n",
    "DEBUG_DF = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get model\n",
    "model = BasicTransformer(dim=DIM, num_embeddings=NUM_WORDS, embedding_dim=DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DATASET == 'yelp':\n",
    "    df = pd.read_csv(\"/media/can/MyData/datasets/yelp/df.csv\")\n",
    "    df['sentiment'] = df['stars'].replace({1: 'negative', 5: 'positive'})\n",
    "    df = df.rename(columns={'text': 'review'})\n",
    "    df = df.sample(n=50_000, random_state=RANDOM_SEED)\n",
    "elif DATASET == 'imdb':\n",
    "    df = pd.read_csv(\"/media/can/MyData/datasets/imdb-50k-movie-review/IMDB Dataset.csv\")\n",
    "else:\n",
    "    raise ValueError(\"Invalid data: {}\".format(str(DATASET)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "txts_positive = df[df['sentiment'] == 'positive']['review'].sample(3).tolist()\n",
    "txts_negative = df[df['sentiment'] == 'negative']['review'].sample(3).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "116.26696"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lens = df['review'].apply(lambda x: len(x.split(' ')))\n",
    "lens.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# generate a fake df for debugging\n",
    "if DEBUG_DF:\n",
    "    n_positive, n_negative = 5000, 5000\n",
    "    positive_label, negative_label = 'positive', 'negative'\n",
    "    positive_text = ' '.join(['good'] * 10)\n",
    "    negative_text = ' '.join(['bad'] * 10)\n",
    "    df = [(positive_text, positive_label)] * n_positive + [(negative_text, negative_label)] * n_negative\n",
    "    df = pd.DataFrame(df)\n",
    "    df.columns = ('review', 'sentiment')\n",
    "    df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = local_util.dataset_generator.TextDataset(df=df, \n",
    "                                                   num_words=NUM_WORDS, \n",
    "                                                   text_column=TEXT_COLUMN, \n",
    "                                                   label_column=LABEL_COLUMN, \n",
    "                                                   label_mapping=LABEL_MAPPING, \n",
    "                                                   max_seq_len=MAX_SEQ_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset=datagen,  \n",
    "                        batch_size=BATCH_SIZE, \n",
    "                        num_workers=multiprocessing.cpu_count(), \n",
    "                        shuffle=SHUFFLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BasicTransformer(\n",
       "  (embed_layer): Embedding(5001, 128)\n",
       "  (linear): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (linear_clf): Linear(in_features=128, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: old comet version (2.0.11) detected. current: 2.0.13 please update your comet lib with command: `pip install --no-cache-dir --upgrade comet_ml`\n",
      "COMET INFO: Experiment is live on comet.ml https://www.comet.ml/a-c-ozbek/basic-transformer-clf-from-scratch/7da3431c065a48cfad4b9e06bf60202a\n",
      "\n",
      "/home/can/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:1350: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/home/can/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py:498: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([16, 1])) is deprecated. Please ensure they have the same size.\n",
      "  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   200] loss: 0.696\n",
      "[1,   400] loss: 0.646\n",
      "[1,   600] loss: 0.583\n",
      "[1,   800] loss: 0.577\n",
      "[1,  1000] loss: 0.552\n",
      "[1,  1200] loss: 0.517\n",
      "[1,  1400] loss: 0.526\n",
      "[1,  1600] loss: 0.513\n",
      "[1,  1800] loss: 0.504\n",
      "[1,  2000] loss: 0.478\n",
      "[1,  2200] loss: 0.483\n",
      "[1,  2400] loss: 0.483\n",
      "[1,  2600] loss: 0.490\n",
      "[1,  2800] loss: 0.473\n",
      "[1,  3000] loss: 0.466\n",
      "\n",
      "[2,   200] loss: 0.719\n",
      "[2,   400] loss: 0.460\n",
      "[2,   600] loss: 0.426\n",
      "[2,   800] loss: 0.428\n",
      "[2,  1000] loss: 0.407\n",
      "[2,  1200] loss: 0.426\n",
      "[2,  1400] loss: 0.412\n",
      "[2,  1600] loss: 0.399\n",
      "[2,  1800] loss: 0.392\n",
      "[2,  2000] loss: 0.421\n",
      "[2,  2200] loss: 0.418\n",
      "[2,  2400] loss: 0.413\n",
      "[2,  2600] loss: 0.409\n",
      "[2,  2800] loss: 0.408\n",
      "[2,  3000] loss: 0.420\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# initialize comet experiment\n",
    "COMET_ML_EXPERIMENT, \\\n",
    "COMET_ML_EXPERIMENT_LINK = initialize_comet_ml_experiment(model_name=local_util.config.PROJECT_NAME, \n",
    "                                                          model_version='x.0.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e415f473756d472facaf8753c5826e0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3125), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f8d20df200e448fbaf9ead7bb0865a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3125), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "losses = list()\n",
    "running_loss = 0.0\n",
    "every = 200\n",
    "# with COMET_ML_EXPERIMENT.train():\n",
    "for epoch in range(2):\n",
    "    for i, x in tqdm_notebook(enumerate(dataloader), total=len(dataloader)):\n",
    "        inputs = x['seq']\n",
    "        labels = x['label'].float()\n",
    "\n",
    "        inputs = inputs.cuda()\n",
    "        labels = labels.cuda()\n",
    "\n",
    "        #\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # \n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "#             if i % 2 == 0:\n",
    "#                 print('loss:', loss)\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % every == every - 1:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / every))\n",
    "            running_loss = 0.0\n",
    "\n",
    "#             COMET_ML_EXPERIMENT.log_metric(\"loss\", loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_layer = torch.nn.Embedding(num_embeddings=17, embedding_dim=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# emb_layer(torch.tensor([0, 0, 10, 16, 17]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
