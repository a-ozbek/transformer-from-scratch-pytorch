{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](./transformer-basics.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicTransformer:\n",
    "    \"\"\"\n",
    "    Basic Transformer\n",
    "    \"\"\"\n",
    "    def __init__(self, dim, avg_out_seq=True):\n",
    "        self.dim = dim\n",
    "        self.avg_out_seq = avg_out_seq\n",
    "        \n",
    "        self.W_q = torch.rand(dim, dim, requires_grad=True)\n",
    "        self.W_k = torch.rand(dim, dim, requires_grad=True)\n",
    "        self.W_v = torch.rand(dim, dim, requires_grad=True)\n",
    "        \n",
    "        self.linear = nn.Linear(dim, dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: \n",
    "            dim0: batch dimension\n",
    "            cols: timesteps (or sequence)\n",
    "            rows: dimensionality (dim)\n",
    "        \"\"\"\n",
    "        q = torch.matmul(self.W_q, x)\n",
    "        k = torch.matmul(self.W_k, x)\n",
    "        v = torch.matmul(self.W_v, x)  # 32 x 8 x 17\n",
    "        \n",
    "        batch_size = x.shape[0]\n",
    "        timesteps = x.shape[2]\n",
    "        \n",
    "        y = torch.empty(batch_size, self.dim, timesteps)\n",
    "        \n",
    "        for i in range(timesteps):\n",
    "            q_i = q[:, :, i]\n",
    "            # get weights\n",
    "            weights = torch.matmul(q_i[:, np.newaxis, :], k).squeeze()\n",
    "            # scale weights\n",
    "            weights = weights / np.sqrt(self.dim)\n",
    "            # softmax weights\n",
    "            print(weights.shape)\n",
    "            weights = torch.softmax(weights, dim=1)\n",
    "            \n",
    "            y[:, :, i] = torch.sum(weights[:, np.newaxis, :] * v, dim=2)\n",
    "            \n",
    "        # apply linear layer to each timestep\n",
    "        y = y.permute(0, 2, 1) # - permute y to be able to apply it\n",
    "        y = self.linear(y)\n",
    "        y = y.permute(0, 2, 1) # - permute back\n",
    "        \n",
    "        if self.avg_out_seq:\n",
    "            y = y.mean(dim=2)  # average out the sequence\n",
    "            \n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
